{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "JrY5UUX0NZue"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -r https://raw.githubusercontent.com/jpcosta90/once-learning/refs/heads/main/scripts/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7UO0WtfNm2w",
        "outputId": "93b0b83c-fafa-4828-9429-1299a8d05fc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------+------------------------------------------+----------------+\n",
            "\u001b[1m\u001b[97m| Model Descriptor                 | Hugging Face Repo                        | Context Length |\u001b[0m\n",
            "+----------------------------------+------------------------------------------+----------------+\n",
            "| Llama3.1-8B                      | meta-llama/Llama-3.1-8B                  | 128K           |\n",
            "+----------------------------------+------------------------------------------+----------------+\n",
            "| Llama3.1-70B                     | meta-llama/Llama-3.1-70B                 | 128K           |\n",
            "+----------------------------------+------------------------------------------+----------------+\n",
            "| Llama3.1-405B:bf16-mp8           | meta-llama/Llama-3.1-405B                | 128K           |\n",
            "+----------------------------------+------------------------------------------+----------------+\n",
            "| Llama3.1-405B                    | meta-llama/Llama-3.1-405B-FP8            | 128K           |\n",
            "+----------------------------------+------------------------------------------+----------------+\n",
            "| Llama3.1-405B:bf16-mp16          | meta-llama/Llama-3.1-405B                | 128K           |\n",
            "+----------------------------------+------------------------------------------+----------------+\n",
            "| Llama3.1-8B-Instruct             | meta-llama/Llama-3.1-8B-Instruct         | 128K           |\n",
            "+----------------------------------+------------------------------------------+----------------+\n",
            "| Llama3.1-70B-Instruct            | meta-llama/Llama-3.1-70B-Instruct        | 128K           |\n",
            "+----------------------------------+------------------------------------------+----------------+\n",
            "| Llama3.1-405B-Instruct:bf16-mp8  | meta-llama/Llama-3.1-405B-Instruct       | 128K           |\n",
            "+----------------------------------+------------------------------------------+----------------+\n",
            "| Llama3.1-405B-Instruct           | meta-llama/Llama-3.1-405B-Instruct-FP8   | 128K           |\n",
            "+----------------------------------+------------------------------------------+----------------+\n",
            "| Llama3.1-405B-Instruct:bf16-mp16 | meta-llama/Llama-3.1-405B-Instruct       | 128K           |\n",
            "+----------------------------------+------------------------------------------+----------------+\n",
            "| Llama3.2-1B                      | meta-llama/Llama-3.2-1B                  | 128K           |\n",
            "+----------------------------------+------------------------------------------+----------------+\n",
            "| Llama3.2-3B                      | meta-llama/Llama-3.2-3B                  | 128K           |\n",
            "+----------------------------------+------------------------------------------+----------------+\n",
            "| Llama3.2-11B-Vision              | meta-llama/Llama-3.2-11B-Vision          | 128K           |\n",
            "+----------------------------------+------------------------------------------+----------------+\n",
            "| Llama3.2-90B-Vision              | meta-llama/Llama-3.2-90B-Vision          | 128K           |\n",
            "+----------------------------------+------------------------------------------+----------------+\n",
            "| Llama3.2-1B-Instruct             | meta-llama/Llama-3.2-1B-Instruct         | 128K           |\n",
            "+----------------------------------+------------------------------------------+----------------+\n",
            "| Llama3.2-3B-Instruct             | meta-llama/Llama-3.2-3B-Instruct         | 128K           |\n",
            "+----------------------------------+------------------------------------------+----------------+\n",
            "| Llama3.2-11B-Vision-Instruct     | meta-llama/Llama-3.2-11B-Vision-Instruct | 128K           |\n",
            "+----------------------------------+------------------------------------------+----------------+\n",
            "| Llama3.2-90B-Vision-Instruct     | meta-llama/Llama-3.2-90B-Vision-Instruct | 128K           |\n",
            "+----------------------------------+------------------------------------------+----------------+\n",
            "| Llama-Guard-3-11B-Vision         | meta-llama/Llama-Guard-3-11B-Vision      | 128K           |\n",
            "+----------------------------------+------------------------------------------+----------------+\n",
            "| Llama-Guard-3-1B:int4-mp1        | meta-llama/Llama-Guard-3-1B-INT4         | 128K           |\n",
            "+----------------------------------+------------------------------------------+----------------+\n",
            "| Llama-Guard-3-1B                 | meta-llama/Llama-Guard-3-1B              | 128K           |\n",
            "+----------------------------------+------------------------------------------+----------------+\n",
            "| Llama-Guard-3-8B                 | meta-llama/Llama-Guard-3-8B              | 128K           |\n",
            "+----------------------------------+------------------------------------------+----------------+\n",
            "| Llama-Guard-3-8B:int8-mp1        | meta-llama/Llama-Guard-3-8B-INT8         | 128K           |\n",
            "+----------------------------------+------------------------------------------+----------------+\n",
            "| Llama-Guard-2-8B                 | meta-llama/Llama-Guard-2-8B              | 4K             |\n",
            "+----------------------------------+------------------------------------------+----------------+\n"
          ]
        }
      ],
      "source": [
        "!llama model list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "wtWkrZ5BSrke"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import snapshot_download\n",
        "import os\n",
        "\n",
        "# Get the token from the environment variable\n",
        "hf_token = os.getenv(\"HF_TOKEN\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oh1vQYXQwQXD",
        "outputId": "199121ce-05ca-47da-d4b1-0c72c7cddcaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())  # Should return True if CUDA is available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4CVIXQY_xk3H"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import re\n",
        "import torch\n",
        "from PIL import Image\n",
        "from transformers import MllamaForConditionalGeneration, AutoProcessor\n",
        "from huggingface_hub import InferenceClient\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "46f93bec925a4169860f3d3486e57bdb",
            "57b9d70fc8df49498ef6db92c1ac900e",
            "666d817f91c4406082be5e7c58a1cbb9",
            "e4bfdf3af2ad4710bd1d03ac47a2b4b9",
            "a306ff5268a4449c92acf56dcb356c19",
            "e33e041199e949bdaf4d4f65518207ca",
            "cbfe6345b20a483b95600deea3ff4ac5",
            "f76f535f1c5645d7ac716042cfec36c1",
            "cd11a56432084312b350a0e1caeae81e",
            "6662077bcd8d4879bd5ebf8218a40c8a",
            "51b532afc2bf47c79161477251fc9f50"
          ]
        },
        "id": "Rcr4lTIzuXfO",
        "outputId": "6335b720-8a6d-40d6-f3ae-9c889eaf6000"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
            "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "46f93bec925a4169860f3d3486e57bdb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 25.2 s, sys: 22 s, total: 47.2 s\n",
            "Wall time: 2min 5s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "model_id = \"meta-llama/Llama-3.2-11B-Vision-Instruct\"\n",
        "\n",
        "model = MllamaForConditionalGeneration.from_pretrained(\n",
        "    model_id,\n",
        "    load_in_4bit=True,\n",
        ")\n",
        "processor = AutoProcessor.from_pretrained(model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2WAvP812rvuH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Carregar o dataframe\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/jpcosta90/once-learning/refs/heads/main/data/one-page-document/one_page_document_complarison_sample.csv')\n",
        "df = df[['file1','file2','same_pattern']]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir a função de comparação\n",
        "def compare_documents(file1, file2):\n",
        "    try:\n",
        "        import requests\n",
        "        from PIL import Image\n",
        "        import re\n",
        "\n",
        "        # URLs base das imagens\n",
        "        base_url = 'https://raw.githubusercontent.com/jpcosta90/once-learning/main/files/'\n",
        "\n",
        "        # Carregar as imagens\n",
        "        reference_image_url = base_url + file1\n",
        "        image_to_classify_url = base_url + file2\n",
        "\n",
        "        reference_image = Image.open(requests.get(reference_image_url, stream=True).raw)\n",
        "        image_to_classify = Image.open(requests.get(image_to_classify_url, stream=True).raw)\n",
        "\n",
        "        # Preparar as mensagens com o prompt ajustado\n",
        "        messages = [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": '''\n",
        "                    Respond with a JSON object with elements status: (standard or out of standard) and justification. Compare two images of company documents, evaluating whether the second document conforms to the standard of the first one in terms of content and layout.\n",
        "\n",
        "                    - **Image 1**: Standard document.\n",
        "                    - **Image 2**: Document to be compared.\n",
        "\n",
        "                    Respond only with a JSON object.\n",
        "\n",
        "                    Do not include any additional text.\n",
        "                    '''},\n",
        "                    {\"type\": \"image\"},  # Imagem de referência\n",
        "                    {\"type\": \"image\"},  # Imagem a ser analisada\n",
        "                ]\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        # Aplicar o template do chat sem adicionar o prompt de geração\n",
        "        input_text = processor.apply_chat_template(messages, add_generation_prompt=False)\n",
        "\n",
        "        # Pré-processar as imagens e o texto\n",
        "        inputs = processor(\n",
        "            images=[reference_image, image_to_classify],\n",
        "            text=input_text,\n",
        "            return_tensors=\"pt\"\n",
        "        ).to(model.device)\n",
        "\n",
        "        # Gerar a resposta\n",
        "        output = model.generate(**inputs, max_new_tokens=200)\n",
        "\n",
        "        # Decodificar a saída e pular tokens especiais\n",
        "        decoded_output = processor.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "        # Extrair apenas a resposta do assistente\n",
        "        assistant_response = decoded_output.strip()\n",
        "\n",
        "        # Usar expressão regular para extrair o objeto JSON\n",
        "        match = re.search(r'\\{.*?\\}', assistant_response, re.DOTALL)\n",
        "        if match:\n",
        "            assistant_response = match.group(0)\n",
        "        else:\n",
        "            assistant_response = \"No valid JSON response.\"\n",
        "\n",
        "        return assistant_response\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\""
      ],
      "metadata": {
        "id": "rk8KzkWi8Vtz"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFcPr2dgCOMy",
        "outputId": "87874fa2-c22e-47b7-ad6f-174cb5bc2d79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [07:21<00:00, 22.06s/it]\n"
          ]
        }
      ],
      "source": [
        "# Aplicar a função ao dataframe\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "df['llama32_response'] = df.progress_apply(\n",
        "    lambda row: compare_documents(row['file1'], row['file2']), axis=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvar o dataframe atualizado\n",
        "df.to_csv('llama_result_sample.csv', index=False)"
      ],
      "metadata": {
        "id": "CzNo1HXnjgJW"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Get the token from the environment variable\n",
        "gh_token = os.getenv(\"GH_TOKEN\")"
      ],
      "metadata": {
        "id": "_VNvwaPaii-k"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import base64\n",
        "\n",
        "# Leitura do arquivo CSV\n",
        "with open('llama_result_sample.csv', 'rb') as f:\n",
        "    content = f.read()\n",
        "\n",
        "# Codificação do conteúdo em base64\n",
        "content_b64 = base64.b64encode(content).decode('utf-8')\n",
        "\n",
        "# Configurar os parâmetros da API\n",
        "repo = 'jpcosta90/once-learning'\n",
        "path = 'results/llama_result_sample.csv'\n",
        "message = 'Adiciona sample_comparisons.csv'\n",
        "token = gh_token"
      ],
      "metadata": {
        "id": "DCN1mRnIiceg"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# URL da API do GitHub\n",
        "url = f'https://api.github.com/repos/{repo}/contents/{path}'\n",
        "\n",
        "# Cabeçalhos da requisição\n",
        "headers = {\n",
        "    'Authorization': f'Bearer {token}',\n",
        "    'Content-Type': 'application/json'\n",
        "}\n",
        "\n",
        "# Dados da requisição\n",
        "data = {\n",
        "    'message': message,\n",
        "    'content': content_b64\n",
        "}\n",
        "\n",
        "# Enviar a requisição PUT\n",
        "response = requests.put(url, headers=headers, json=data)\n",
        "\n",
        "# Verificar a resposta\n",
        "if response.status_code == 201:\n",
        "    print('Arquivo enviado com sucesso!')\n",
        "else:\n",
        "    print(f'Erro ao enviar o arquivo: {response.content}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOufPx_Sj57R",
        "outputId": "d82eb7df-afbf-45fb-fd99-2602b552d8b9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Erro ao enviar o arquivo: b'{\"message\":\"Bad credentials\",\"documentation_url\":\"https://docs.github.com/rest\",\"status\":\"401\"}'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar autenticação do token\n",
        "response = requests.get('https://api.github.com/user', headers=headers)\n",
        "if response.status_code == 200:\n",
        "    print('Autenticação bem-sucedida!')\n",
        "    print(f\"Usuário autenticado: {response.json()['login']}\")\n",
        "else:\n",
        "    print(f\"Erro na autenticação: {response.content}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xh6W914Ak78z",
        "outputId": "b89e7be8-da4a-464d-f29e-7f5045817527"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Erro na autenticação: b'{\"message\":\"Bad credentials\",\"documentation_url\":\"https://docs.github.com/rest\",\"status\":\"401\"}'\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "46f93bec925a4169860f3d3486e57bdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_57b9d70fc8df49498ef6db92c1ac900e",
              "IPY_MODEL_666d817f91c4406082be5e7c58a1cbb9",
              "IPY_MODEL_e4bfdf3af2ad4710bd1d03ac47a2b4b9"
            ],
            "layout": "IPY_MODEL_a306ff5268a4449c92acf56dcb356c19"
          }
        },
        "57b9d70fc8df49498ef6db92c1ac900e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e33e041199e949bdaf4d4f65518207ca",
            "placeholder": "​",
            "style": "IPY_MODEL_cbfe6345b20a483b95600deea3ff4ac5",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "666d817f91c4406082be5e7c58a1cbb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f76f535f1c5645d7ac716042cfec36c1",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd11a56432084312b350a0e1caeae81e",
            "value": 5
          }
        },
        "e4bfdf3af2ad4710bd1d03ac47a2b4b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6662077bcd8d4879bd5ebf8218a40c8a",
            "placeholder": "​",
            "style": "IPY_MODEL_51b532afc2bf47c79161477251fc9f50",
            "value": " 5/5 [02:00&lt;00:00, 20.77s/it]"
          }
        },
        "a306ff5268a4449c92acf56dcb356c19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e33e041199e949bdaf4d4f65518207ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbfe6345b20a483b95600deea3ff4ac5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f76f535f1c5645d7ac716042cfec36c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd11a56432084312b350a0e1caeae81e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6662077bcd8d4879bd5ebf8218a40c8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51b532afc2bf47c79161477251fc9f50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}